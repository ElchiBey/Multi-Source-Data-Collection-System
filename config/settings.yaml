# Multi-Source Data Collection System Configuration

# Scraping Configuration
scraping:
  # Delay between requests (seconds)
  delay_range: [1, 3]
  
  # Maximum retry attempts
  max_retries: 3
  
  # Request timeout (seconds)
  timeout: 30
  
  # Use random user agents
  user_agents: true
  
  # Maximum pages per source
  max_pages: 10
  
  # Concurrent workers
  max_workers: 5

# Database Configuration
database:
  # SQLite database URL
  url: "sqlite:///data/products.db"
  
  # Enable query logging
  echo: false
  
  # Connection pool settings
  pool_size: 10
  max_overflow: 20

# Sources Configuration
sources:
  amazon:
    enabled: true
    base_url: "https://www.amazon.com"
    search_path: "/s?k={keyword}&page={page}"
    delay_range: [2, 4]
    
  ebay:
    enabled: true
    base_url: "https://www.ebay.com"
    search_path: "/sch/i.html?_nkw={keyword}&_pgn={page}"
    delay_range: [1, 3]
    
  walmart:
    enabled: true
    base_url: "https://www.walmart.com"
    search_path: "/search/?query={keyword}&page={page}"
    delay_range: [2, 3]

# Selenium Configuration
selenium:
  # Chrome driver settings
  chrome_options:
    - "--headless"
    - "--no-sandbox"
    - "--disable-dev-shm-usage"
    - "--disable-gpu"
    - "--window-size=1920,1080"
    - "--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
  
  # Wait timeouts
  implicit_wait: 10
  page_load_timeout: 30

# Scrapy Configuration
scrapy:
  # Custom settings
  settings:
    ROBOTSTXT_OBEY: true
    DOWNLOAD_DELAY: 2
    RANDOMIZE_DOWNLOAD_DELAY: 0.5
    CONCURRENT_REQUESTS: 16
    CONCURRENT_REQUESTS_PER_DOMAIN: 8
    COOKIES_ENABLED: true
    TELNETCONSOLE_ENABLED: false

# Data Processing
processing:
  # Data cleaning settings
  clean_html: true
  normalize_prices: true
  remove_duplicates: true
  
  # Validation rules
  min_price: 0.01
  max_price: 100000
  
  # Price extraction patterns
  price_patterns:
    - r'\$?(\d+(?:,\d{3})*(?:\.\d{2})?)'
    - r'USD\s*(\d+(?:,\d{3})*(?:\.\d{2})?)'

# Export Configuration
export:
  # Supported formats
  formats: ["csv", "json", "excel"]
  
  # Default output directory
  output_dir: "data_output"
  
  # File naming
  timestamp_format: "%Y%m%d_%H%M%S"

# Logging Configuration
logging:
  # Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
  level: "INFO"
  
  # Log format
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  
  # Log files
  file: "logs/scraper.log"
  max_bytes: 10485760  # 10MB
  backup_count: 5

# Analysis Configuration
analysis:
  # Trend analysis settings
  trend_periods: [7, 14, 30, 90]
  
  # Statistical methods
  statistics: ["mean", "median", "std", "min", "max"]
  
  # Visualization settings
  chart_style: "seaborn"
  figure_size: [12, 8]
  dpi: 300

# Security Settings
security:
  # Rate limiting
  rate_limit: true
  requests_per_minute: 30
  
  # Proxy settings
  use_proxies: true
  proxy_list: ["http://127.0.0.1:9090", "http://proxy1:port", "http://proxy2:port"]
  
  # User agent rotation
  rotate_user_agents: true 

